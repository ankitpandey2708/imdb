{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decide interval and no of pages\n",
    "a=int(input(\"From : \"))\n",
    "b=int(input(\"To : \"))\n",
    "c=int(input(\"No of pages to be scraped per year : \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = [str(i) for i in range(1,c+1)]\n",
    "years_url = [str(i) for i in range(a,b+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For every year in the interval\n",
    "for year_url in years_url:\n",
    "    \n",
    "    # For every page\n",
    "    for page in pages:\n",
    "        \n",
    "        # Make a get request\n",
    "        response = requests.get('http://www.imdb.com/search/title?release_date=' + year_url + \n",
    "        '&sort=num_votes,desc&page=' + page)\n",
    "        \n",
    "        # Pause the loop\n",
    "        sleep(5)\n",
    "        \n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Select all the 50 movie containers from a single page\n",
    "        mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "        \n",
    "        # For every movie of these 50\n",
    "        for container in mv_containers:\n",
    "            # If the movie has a Metascore, then:\n",
    "            if container.find('div', class_ = 'ratings-metascore') is not None:\n",
    "                \n",
    "                # Scrape the name\n",
    "                name = container.h3.a.text\n",
    "                names.append(name)\n",
    "                \n",
    "                # Scrape the year \n",
    "                year = container.h3.find('span', class_ = 'lister-item-year').text\n",
    "                years.append(year)\n",
    "\n",
    "                # Scrape the IMDB rating\n",
    "                imdb = float(container.strong.text)\n",
    "                imdb_ratings.append(imdb)\n",
    "\n",
    "                # Scrape the Metascore\n",
    "                m_score = container.find('span', class_ = 'metascore').text\n",
    "                metascores.append(int(m_score))\n",
    "\n",
    "                # Scrape the number of votes\n",
    "                vote = container.find('span', attrs = {'name':'nv'})['data-value']\n",
    "                votes.append(int(vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_ratings = pd.DataFrame({'movie': names,'year': years,'imdb': imdb_ratings,'metascore': metascores,'votes': votes})\n",
    "\n",
    "#reorder column\n",
    "movie_ratings = movie_ratings[['movie', 'year', 'imdb', 'metascore', 'votes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert year to int\n",
    "movie_ratings.loc[:, 'year'] = movie_ratings['year'].str[-5:-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#multiply imdb by 10\n",
    "movie_ratings['n_imdb'] = movie_ratings['imdb'] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save dataset\n",
    "movie_ratings.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot graphs\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (11,4))\n",
    "ax1, ax2, ax3 = fig.axes\n",
    "\n",
    "ax1.hist(movie_ratings['imdb'], bins = 10, range = (0,10))\n",
    "ax1.set_title('IMDB rating')\n",
    "\n",
    "ax2.hist(movie_ratings['metascore'], bins = 10, range = (0,100))\n",
    "ax2.set_title('Metascore')\n",
    "\n",
    "ax3.hist(movie_ratings['n_imdb'], bins = 10, range = (0,100), histtype = 'step')\n",
    "ax3.hist(movie_ratings['metascore'], bins = 10, range = (0,100), histtype = 'step')\n",
    "ax3.legend(loc = 'upper left')\n",
    "ax3.set_title('The Two Normalized Distributions')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
